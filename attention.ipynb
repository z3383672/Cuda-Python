{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "def replicate(layer,N):\n",
    "    return nn.ModuleList([layer for _ in range(N)])\n",
    "\n",
    "class Encode(nn.Module):\n",
    "\n",
    "    def __init__(self,layer,N):\n",
    "        super(Encode, self).__init__()\n",
    "        self.layer=replicate(layer,N)\n",
    "        self.N=N\n",
    "\n",
    "    def forward(self,X,mask):\n",
    "        for layer in self.layer:\n",
    "            X=layer(X,mask)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self,features,eps=1e-16):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2=nn.Parameter(torch.ones(features))\n",
    "        self.b_2=nn.Parameter(torch.zeros(features))\n",
    "        self.eps=eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, size, dropout_rate, eps=1e-6):\n",
    "        super(AddNorm, self).__init__()\n",
    "        \n",
    "        # Layer normalization component\n",
    "        self.norm = LayerNorm(size, eps=eps)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, sublayer_output):\n",
    "        \"Apply residual connection followed by layer normalization\"\n",
    "        # Residual connection\n",
    "        added_output = x + self.dropout(sublayer_output)\n",
    "        \n",
    "        # Layer normalization\n",
    "        return self.norm(added_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        d_model: the number of expected features in the input (required).\n",
    "        d_ff: the number of features of the feedforward network model.\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        \"\"\"\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        # Two linear layers with a ReLU activation in between\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "        torch.uint8\n",
    "    )\n",
    "    return subsequent_mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def attention(query,Q,K,V):\n",
    "    #K transpose might cause a trpoouble if we have multi dimntioanmatrix\n",
    "    scores=torch.matmul(Q,K.T)/math.sqrt(d_k)\n",
    "    p_atten=scores.softmax(scores, dim=2)\n",
    "    return torch.matmul(p_atten,V),p_atten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key,value,mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Linear layers\n",
    "        Q = self.query(query)\n",
    "        K = self.key(key)\n",
    "        V = self.value(value)\n",
    "\n",
    "        # Split into multiple heads\n",
    "        Q = Q.view(batch_size, -1, self.num_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.num_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.num_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        attention_scores = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.d_k**0.5\n",
    "        if mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
    "        attention_probs = F.softmax(attention_scores, dim=-1)\n",
    "        attention_output = torch.matmul(attention_probs, V)\n",
    "\n",
    "        # Concatenate heads and pass through final linear layer\n",
    "        attention_output = attention_output.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.d_k * self.num_heads)\n",
    "        output = self.fc_out(attention_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, size, FeedForward, Multi_Head_Attention,AddNorm):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.self_attn = Multi_Head_Attention\n",
    "        self.feed_forward = FeedForward\n",
    "        self.AddNorm=AddNorm\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self,x,mask):\n",
    "        x=self.AddNorm(x, self.self_attn(x,x,x,mask))\n",
    "        x=self.AddNorm(x, self.feed_forward(x))\n",
    "        return x      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src=torch.LongTensor([0,1,2,3,4,5,6,7,8,9])\n",
    "# tgt=torch.LongTensor([0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "# model=Encoder_Decoder(\n",
    "#         Encode(Encoder(512,FeedForward(512, 2048, dropout=0.1), MultiHeadAttention(512, 8),AddNorm(512, 0.1, eps=1e-6)),6),\n",
    "#         Decode(Decoder(512, FeedForward(512, 2048, dropout=0.1), MultiHeadAttention(512, 8),MultiHeadAttention(512,8)),6),\n",
    "#         nn.Sequential(Embedding(512,10),Positional_Encoding(512)),\n",
    "#         nn.Sequential(Embedding(512,10),Positional_Encoding(512)),\n",
    "#         Generator(512,10)\n",
    "#     )\n",
    "# A=model.src_embed(src)\n",
    "# B=model.Encode(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 512])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B=MultiHeadAttention(512, 8)\n",
    "# B(A,A,A).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this might be a replicate\n",
    "class Decode(nn.Module):\n",
    "\n",
    "    def __init__(self,layer,N):\n",
    "        super(Decode, self).__init__()\n",
    "        self.layer=replicate(layer,N)\n",
    "        self.N=N\n",
    "\n",
    "    def forward(self,X,y,src_mask,tgt_mask):\n",
    "        for layer in self.layer:\n",
    "            X=layer(X,y,src_mask,tgt_mask)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, size, FeedForward, Self_Multi_Head_Attention,Encoder_Multi_Head_Attention):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.self_attn = Self_Multi_Head_Attention\n",
    "        self.feed_forward = FeedForward\n",
    "        self.encoder_attention=Encoder_Multi_Head_Attention\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self,x,m,src_mask,tgt_mask):\n",
    "        x=self.AddNorm(x, self.self_attn(x,x,x,tgt_mask))\n",
    "        x=self.AddNorm(x, self.encoder_attention(x,m,m,src_mask))\n",
    "        x=self.AddNorm(x, FeedForward(x))\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, d_model,vocab):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding=nn.Embedding(vocab,d_model)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.embedding(x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Positional_Encoding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(Positional_Encoding, self).__init__()\n",
    "        self.dmodel=d_model\n",
    "        \n",
    "    def forward(self,x):\n",
    "        n=x.shape[0]\n",
    "        div_term = torch.exp(torch.arange(0., self.dmodel, 2) * -(math.log(10000.0) / self.dmodel))\n",
    "\n",
    "        positions = torch.arange(n).unsqueeze(1).float()\n",
    "        div_term = div_term.unsqueeze(0)\n",
    "        sin_vals = torch.sin(positions * div_term)\n",
    "        cos_vals = torch.cos(positions * div_term)\n",
    "\n",
    "        ZZ = torch.empty(n, self.dmodel)\n",
    "        ZZ[:, 0::2] = sin_vals\n",
    "        ZZ[:, 1::2] = cos_vals\n",
    "        return x+ZZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Positional_Encoding(Embeded):\n",
    "#     n=Embeded.shape[0]\n",
    "#     dmodel=Embeded.shape[1]\n",
    "#     div_term = torch.exp(torch.arange(0., dmodel, 2) * -(math.log(10000.0) / dmodel))\n",
    "\n",
    "#     # Expand dimensions for broadcasting\n",
    "#     positions = torch.arange(n).unsqueeze(1).float()\n",
    "#     div_term = div_term.unsqueeze(0)\n",
    "\n",
    "#     # Calculate sin and cos values\n",
    "#     sin_vals = torch.sin(positions * div_term)\n",
    "#     cos_vals = torch.cos(positions * div_term)\n",
    "\n",
    "#     # Interleave sin and cos values\n",
    "#     ZZ = torch.empty(n, dmodel)\n",
    "#     ZZ[:, 0::2] = sin_vals\n",
    "#     ZZ[:, 1::2] = cos_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Decoder(nn.Module):\n",
    "    def __init__(self, Encode,Decode,src_embed, tgt_embed, generator):\n",
    "        super(Encoder_Decoder, self).__init__()\n",
    "        self.Encode=Encode\n",
    "        self.Decode=Decode\n",
    "        self.src_embed=src_embed\n",
    "        self.tgt_embed=tgt_embed\n",
    "        self.generator=generator\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.Encode(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.Decode(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,d_model,tgt_vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.linear=nn.Linear(d_model,tgt_vocab)\n",
    "\n",
    "    def forward(sefl,x):\n",
    "        x=self.linear(x)\n",
    "        return log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab,tgt_vocab,N=6,d_model=512,h=8,dropout=0.1,d_ff=2048):\n",
    "    \n",
    "    model=Encoder_Decoder(\n",
    "        Encode(Encoder(d_model,FeedForward(d_model, d_ff, dropout=dropout), MultiHeadAttention(d_model, h),AddNorm(d_model,dropout, eps=1e-6)),N),\n",
    "        Decode(Decoder(d_model, FeedForward(d_model, d_ff, dropout=dropout), MultiHeadAttention(d_model, h),MultiHeadAttention(d_model,h)),N),\n",
    "        nn.Sequential(Embedding(d_model,src_vocab),Positional_Encoding(d_model)),\n",
    "        nn.Sequential(Embedding(d_model,tgt_vocab),Positional_Encoding(d_model)),\n",
    "        Generator(d_model,tgt_vocab)\n",
    "    )\n",
    "    for p in model.parameters():\n",
    "        if p.dim()>1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-353-b8f474b3ede9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     out = test_model.decode(\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsequent_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         )\n",
      "\u001b[1;32m<ipython-input-341-d19b092c37be>\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, memory, src_mask, tgt, tgt_mask)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtgt_embed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\61401\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\61401\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\61401\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-300-9c726b922ec2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\61401\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\61401\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32mc:\\Users\\61401\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2208\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "test_model = make_model(11, 11, 2)\n",
    "test_model.eval()\n",
    "src = torch.LongTensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "src_mask = torch.ones(1, 1, 10)\n",
    "memory = test_model.encode(src, src_mask)\n",
    "ys = torch.zeros(1, 1).type_as(src)\n",
    "\n",
    "\n",
    "for i in range(9):\n",
    "    out = test_model.decode(\n",
    "        memory, src_mask, embed_ys, subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "        )\n",
    "    prob = test_model.generator(out[:, -1])\n",
    "    _, next_word = torch.max(prob, dim=1)\n",
    "    next_word = next_word.data[0]\n",
    "    ys = torch.cat(\n",
    "        [ys, torch.empty(1, 1).type_as(src.data).fill_(next_word)], dim=1\n",
    "    )\n",
    "\n",
    "print(\"Example Untrained Model Prediction:\", ys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import math \n",
    "import torch.nn.functional as F\n",
    "\n",
    "def replicate(layer,N):\n",
    "    return nn.ModuleList([layer for _ in range(N)])\n",
    "\n",
    "class Encode(nn.Module):\n",
    "\n",
    "    def __init__(self,layer,N):\n",
    "        super(Encode, self).__init__()\n",
    "        self.layer=replicate(layer,N)\n",
    "        self.N=N\n",
    "\n",
    "    def forward(self,X,mask):\n",
    "        for layer in self.layer:\n",
    "            X=layer(X,mask)\n",
    "        return X\n",
    "    \n",
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self,features,eps=1e-16):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2=nn.Parameter(torch.ones(features))\n",
    "        self.b_2=nn.Parameter(torch.zeros(features))\n",
    "        self.eps=eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "    \n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, size, dropout_rate, eps=1e-6):\n",
    "        super(AddNorm, self).__init__()\n",
    "        \n",
    "        # Layer normalization component\n",
    "        self.norm = LayerNorm(size, eps=eps)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, sublayer_output):\n",
    "        \"Apply residual connection followed by layer normalization\"\n",
    "        # Residual connection\n",
    "        added_output = x + self.dropout(sublayer_output)\n",
    "        \n",
    "        # Layer normalization\n",
    "        return self.norm(added_output)\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        d_model: the number of expected features in the input (required).\n",
    "        d_ff: the number of features of the feedforward network model.\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        \"\"\"\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        # Two linear layers with a ReLU activation in between\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "    \n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "        torch.uint8\n",
    "    )\n",
    "    return subsequent_mask == 0\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key,value,mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Linear layers\n",
    "        Q = self.query(query)\n",
    "        K = self.key(key)\n",
    "        V = self.value(value)\n",
    "\n",
    "        # Split into multiple heads\n",
    "        Q = Q.view(batch_size, -1, self.num_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.num_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.num_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        attention_scores = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.d_k**0.5\n",
    "        if mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
    "        attention_probs = F.softmax(attention_scores, dim=-1)\n",
    "        attention_output = torch.matmul(attention_probs, V)\n",
    "\n",
    "        # Concatenate heads and pass through final linear layer\n",
    "        attention_output = attention_output.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.d_k * self.num_heads)\n",
    "        output = self.fc_out(attention_output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, size, FeedForward, Multi_Head_Attention,AddNorm):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.self_attn = Multi_Head_Attention\n",
    "        self.feed_forward = FeedForward\n",
    "        self.AddNorm=AddNorm\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self,x,mask):\n",
    "        x=self.AddNorm(x, self.self_attn(x,x,x,mask))\n",
    "        x=self.AddNorm(x, self.feed_forward(x))\n",
    "        return x  \n",
    "    \n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, d_model,vocab):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding=nn.Embedding(vocab,d_model)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.embedding(x)   \n",
    "    \n",
    "class Positional_Encoding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(Positional_Encoding, self).__init__()\n",
    "        self.dmodel=d_model\n",
    "        \n",
    "    def forward(self,x):\n",
    "        n=x.shape[0]\n",
    "        div_term = torch.exp(torch.arange(0., self.dmodel, 2) * -(math.log(10000.0) / self.dmodel))\n",
    "\n",
    "        positions = torch.arange(n).unsqueeze(1).float()\n",
    "        div_term = div_term.unsqueeze(0)\n",
    "        sin_vals = torch.sin(positions * div_term)\n",
    "        cos_vals = torch.cos(positions * div_term)\n",
    "\n",
    "        ZZ = torch.empty(n, self.dmodel)\n",
    "        ZZ[:, 0::2] = sin_vals\n",
    "        ZZ[:, 1::2] = cos_vals\n",
    "        return x+ZZ\n",
    "    \n",
    "def make_model(src_vocab,tgt_vocab,N=6,d_model=512,h=8,dropout=0.1,d_ff=2048):\n",
    "    \n",
    "    model=Encoder_Decoder(\n",
    "        Encode(Encoder(d_model,FeedForward(d_model, d_ff, dropout=dropout), MultiHeadAttention(d_model, h),AddNorm(d_model,dropout, eps=1e-6)),N),\n",
    "        Decode(Decoder(d_model, FeedForward(d_model, d_ff, dropout=dropout), MultiHeadAttention(d_model, h),MultiHeadAttention(d_model,h)),N),\n",
    "        nn.Sequential(Embedding(d_model,src_vocab),Positional_Encoding(d_model)),\n",
    "        nn.Sequential(Embedding(d_model,tgt_vocab),Positional_Encoding(d_model)),\n",
    "        Generator(d_model,tgt_vocab)\n",
    "    )\n",
    "    for p in model.parameters():\n",
    "        if p.dim()>1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,d_model,tgt_vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.linear=nn.Linear(d_model,tgt_vocab)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.linear(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "    \n",
    "\n",
    "class Encoder_Decoder(nn.Module):\n",
    "    def __init__(self, Encode,Decode,src_embed, tgt_embed, generator):\n",
    "        super(Encoder_Decoder, self).__init__()\n",
    "        self.Encode=Encode\n",
    "        self.Decode=Decode\n",
    "        self.src_embed=src_embed\n",
    "        self.tgt_embed=tgt_embed\n",
    "        self.generator=generator\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.Encode(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.Decode(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "    \n",
    "class Decode(nn.Module):\n",
    "\n",
    "    def __init__(self,layer,N):\n",
    "        super(Decode, self).__init__()\n",
    "        self.layer=replicate(layer,N)\n",
    "        self.N=N\n",
    "\n",
    "    def forward(self,X,y,src_mask,tgt_mask):\n",
    "        for layer in self.layer:\n",
    "            X=layer(X,y,src_mask,tgt_mask)\n",
    "        return X\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, size, FeedForward, Self_Multi_Head_Attention,Encoder_Multi_Head_Attention,AddNorm):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.self_attn = Self_Multi_Head_Attention\n",
    "        self.feed_forward = FeedForward\n",
    "        self.encoder_attention=Encoder_Multi_Head_Attention\n",
    "        self.AddNorm=AddNorm\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self,x,m,src_mask,tgt_mask):\n",
    "        x=self.AddNorm(x, self.self_attn(x,x,x,tgt_mask))\n",
    "        x=self.AddNorm(x, self.encoder_attention(x,m,m,src_mask))\n",
    "        x=self.AddNorm(x, self.feed_forward(x))\n",
    "        return x   \n",
    "    \n",
    "def make_model(src_vocab,tgt_vocab,N=6,d_model=512,h=8,dropout=0.1,d_ff=2048):\n",
    "    \n",
    "    model=Encoder_Decoder(\n",
    "        Encode(Encoder(d_model,FeedForward(d_model, d_ff, dropout=dropout), MultiHeadAttention(d_model, h),AddNorm(d_model,dropout, eps=1e-6)),N),\n",
    "        Decode(Decoder(d_model, FeedForward(d_model, d_ff, dropout=dropout), MultiHeadAttention(d_model, h),MultiHeadAttention(d_model,h),AddNorm(d_model,dropout, eps=1e-6)),N),\n",
    "        nn.Sequential(Embedding(d_model,src_vocab),Positional_Encoding(d_model)),\n",
    "        nn.Sequential(Embedding(d_model,tgt_vocab),Positional_Encoding(d_model)),\n",
    "        Generator(d_model,tgt_vocab)\n",
    "    )\n",
    "    for p in model.parameters():\n",
    "        if p.dim()>1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Encode.layer.0.self_attn.query.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.self_attn.query.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.self_attn.key.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.self_attn.key.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.self_attn.value.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.self_attn.value.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.self_attn.fc_out.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.self_attn.fc_out.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.feed_forward.w_1.weight, Size: torch.Size([2048, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.feed_forward.w_1.bias, Size: torch.Size([2048]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.feed_forward.w_2.weight, Size: torch.Size([512, 2048]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.feed_forward.w_2.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.AddNorm.norm.a_2, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Encode.layer.0.AddNorm.norm.b_2, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.self_attn.query.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.self_attn.query.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.self_attn.key.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.self_attn.key.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.self_attn.value.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.self_attn.value.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.self_attn.fc_out.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.self_attn.fc_out.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.feed_forward.w_1.weight, Size: torch.Size([2048, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.feed_forward.w_1.bias, Size: torch.Size([2048]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.feed_forward.w_2.weight, Size: torch.Size([512, 2048]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.feed_forward.w_2.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.encoder_attention.query.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.encoder_attention.query.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.encoder_attention.key.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.encoder_attention.key.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.encoder_attention.value.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.encoder_attention.value.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.encoder_attention.fc_out.weight, Size: torch.Size([512, 512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.encoder_attention.fc_out.bias, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.AddNorm.norm.a_2, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: Decode.layer.0.AddNorm.norm.b_2, Size: torch.Size([512]) ,f\"Requires Grad: True\"\n",
      "Name: src_embed.0.embedding.weight, Size: torch.Size([11, 512]) ,f\"Requires Grad: True\"\n",
      "Name: tgt_embed.0.embedding.weight, Size: torch.Size([11, 512]) ,f\"Requires Grad: True\"\n",
      "Name: generator.linear.weight, Size: torch.Size([11, 512]) ,f\"Requires Grad: True\"\n",
      "Name: generator.linear.bias, Size: torch.Size([11]) ,f\"Requires Grad: True\"\n"
     ]
    }
   ],
   "source": [
    "test_model = make_model(11, 11, 2)\n",
    "for name, param in test_model.named_parameters():\n",
    "    print(f'Name: {name}, Size: {param.size()} ,f\"Requires Grad: {param.requires_grad}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self,src,tgt,pad=2):\n",
    "        self.src=src\n",
    "        self.src_mask=(src!=pad).unsqueeze(-2)\n",
    "        self.tgt=tgt[:,:-1]\n",
    "        self.tgt_y=tgt[:,1:]\n",
    "        self.tgt_mask=self.make_std_mask(self.tgt,pad)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt,pad):\n",
    "        tgt_mask=(tgt!=pad).unsqueeze(-2)\n",
    "        tgt_mask=tgt_mask & subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data)\n",
    "        return tgt_mask  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(V,batch_size,n_batches):\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        # Get the data and labels for the current batch\n",
    "        data=torch.randint(1,V,size=(batch_size,10))\n",
    "        data[:,0]=1\n",
    "        src=data.requires_grad_(False).clone().detach()\n",
    "        tgt=data.requires_grad_(False).clone().detach()\n",
    "        yield Batch(src,tgt,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction=\"sum\")\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, true_dist.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512])\n",
      "torch.Size([1, 2, 512])\n",
      "torch.Size([1, 3, 512])\n",
      "torch.Size([1, 4, 512])\n",
      "torch.Size([1, 5, 512])\n",
      "torch.Size([1, 6, 512])\n",
      "torch.Size([1, 7, 512])\n",
      "torch.Size([1, 8, 512])\n",
      "torch.Size([1, 9, 512])\n",
      "tensor([[ 1,  4,  1,  1,  6,  3,  4,  4,  3, 10]])\n",
      "tensor([[0, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "# test_model = make_model(11, 11, 2)\n",
    "# for batch in data_gen(11,1,1):\n",
    "#     out=test_model.forward(batch.src,batch.tgt,batch.src_mask,batch.tgt_mask)\n",
    "\n",
    "# out=test_model.generator(out)\n",
    "\n",
    "\n",
    "for batch in data_gen(11,1,1):\n",
    "    memory = test_model.encode(batch.src, batch.src_mask)\n",
    "    ys = torch.zeros(1, 1).fill_(0).type_as(batch.src.data)\n",
    "    for i in range(10 - 1):\n",
    "        out = test_model.decode(\n",
    "            memory, batch.src_mask, ys, subsequent_mask(ys.size(1)).type_as(batch.src.data)\n",
    "        )\n",
    "        print(out.shape)\n",
    "        prob = test_model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.zeros(1, 1).type_as(batch.src.data).fill_(next_word)], dim=1\n",
    "        )\n",
    "print(batch.src)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.5780, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = make_model(11, 11, 2)\n",
    "for batch in data_gen(11,1,1):\n",
    "    out=test_model.forward(batch.src,batch.tgt,batch.src_mask,batch.tgt_mask)\n",
    "\n",
    "out=test_model.generator(out)\n",
    "criterion=LabelSmoothing(11,0,0.0)\n",
    "criterion(out.contiguous().view(-1,out.size(-1)),batch.tgt_y.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numpy_array = out.detach().numpy()\n",
    "\n",
    "# Save the numpy array to a CSV file\n",
    "np.savetxt('tensor.csv', numpy_array[0], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate(step_num,d_model,factor,warmup_steps):\n",
    "    if step_num==0:\n",
    "        step_num=1\n",
    "    return d_model**(-0.5) * min(step_num**(-0.5), step_num * warmup_steps**(-1.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (20) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-1774ac2c9be6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# Compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-d5a1d609a176>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;34m\"Take in and process masked src and target sequences.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-d5a1d609a176>\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, src, src_mask)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEncode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc_embed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\61401\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\61401\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\61401\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-d5a1d609a176>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mZZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msin_vals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mZZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcos_vals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mZZ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_vocab\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtgt_vocab\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_ff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (20) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "test_model = make_model(11, 11, 2)\n",
    "criterion=LabelSmoothing(11,0,0.0)\n",
    "optimizer = torch.optim.Adam(test_model.parameters(), lr=1)\n",
    "lr_lambda = lambda step: rate(step,256,1,4000)\n",
    "\n",
    "# Create a LambdaLR scheduler\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for i,batch in enumerate(data_gen(11,20,30)):  # Assume data_loader is an iterator that provides batches of data\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get the data and labels\n",
    "        \n",
    "        # Forward pass\n",
    "        out = test_model.forward(batch.src,batch.tgt,batch.src_mask,batch.tgt_mask)\n",
    "        out=test_model.generator(out)\n",
    "        # Compute loss\n",
    "        loss = criterion(out.contiguous().view(-1,out.size(-1)),batch.tgt_y.contiguous().view(-1))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    data=torch.randint(1,11,size=(50,10))\n",
    "    data[:,0]=1\n",
    "    src=data.requires_grad_(False).clone().detach()\n",
    "    tgt=data.requires_grad_(False).clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5584)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the loss function with reduction set to 'sum'\n",
    "loss_function = nn.KLDivLoss(reduction='sum')\n",
    "\n",
    "# Define two probability distributions (as PyTorch tensors)\n",
    "# Input (log probabilities)\n",
    "input = torch.tensor([[0.2, 0.7, 0.1], [0.9, 0.05, 0.05]], dtype=torch.float).log()\n",
    "# Target (probabilities)\n",
    "target = torch.tensor([[0.1, 0.8, 0.1], [0.5, 0.2, 0.3]], dtype=torch.float)\n",
    "\n",
    "# Compute the loss\n",
    "loss = loss_function(input, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label smoothing\n",
    "size=6\n",
    "padding_idx=0\n",
    "smoothing=0.4\n",
    "predict=torch.FloatTensor([[0,0.2,0.7,0.1,0],\n",
    "                           [0,0.2,0.7,0.1,0],\n",
    "                           [0,0.2,0.7,0.1,0],\n",
    "                           [0,0.2,0.7,0.1,0],\n",
    "                           [0,0.2,0.7,0.1,0],\n",
    "                           [0,0.2,0.7,0.1,0]])\n",
    "target=torch.LongTensor([2,1,0,3,3,4])\n",
    "true_dist = predict.log().data.clone()\n",
    "true_dist.fill_(smoothing / (size - 2))\n",
    "true_dist.scatter_(1, target.data.unsqueeze(1), 0.6)\n",
    "true_dist[:, padding_idx] = 0\n",
    "mask = torch.nonzero(target.data == padding_idx)\n",
    "if mask.dim() > 0:\n",
    "    true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "s=loss_function(predict.log(), true_dist.clone().detach())\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "crit = LabelSmoothing(5, 0, 0.4)\n",
    "predict = torch.FloatTensor(\n",
    "    [\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "    ]\n",
    ")\n",
    "crit(x=predict.log(), target=torch.LongTensor([2, 1, 0, 3, 3]))\n",
    "LS_data = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                    \"target distribution\": crit.true_dist[x, y].flatten(),\n",
    "                    \"columns\": y,\n",
    "                    \"rows\": x,\n",
    "            }\n",
    "        )\n",
    "        for y in range(5)\n",
    "        for x in range(5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# alt.Chart(LS_data)\n",
    "# .mark_rect(color=\"Blue\", opacity=1)\n",
    "# .properties(height=200, width=200)\n",
    "# .encode(\n",
    "#     alt.X(\"columns:O\", title=None),\n",
    "#     alt.Y(\"rows:O\", title=None),\n",
    "#     alt.Color(\n",
    "#         \"target distribution:Q\", scale=alt.Scale(scheme=\"viridis\")\n",
    "#     ),\n",
    "# )\n",
    "# .interactive()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit(x=predict.log(), target=torch.LongTensor([2, 1, 0, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader:  # Assume data_loader is an iterator that provides batches of data\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get the data and labels\n",
    "        inputs, labels = batch\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: weight, Size: torch.Size([1, 1])\n",
      "Name: bias, Size: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, param in dummy_mode.named_parameters():\n",
    "    print(f'Name: {name}, Size: {param.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0266]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_mode.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n",
      "tensor([[-0.5570]])\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "dummy_mode=nn.Linear(1,1)\n",
    "learning_rate=[]\n",
    "optimizer = torch.optim.Adam(dummy_mode.parameters(), lr=1)\n",
    "\n",
    "lr_lambda = lambda step: rate(step,256,1,4000)\n",
    "\n",
    "# Create a LambdaLR scheduler\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "tem=[]\n",
    "for epoch in range(20):\n",
    "    # (Here you would normally perform the training steps)\n",
    "    optimizer.zero_grad()\n",
    "    # Step the scheduler to adjust the learning rate\n",
    "    tem.append(optimizer.param_groups[0][\"lr\"])\n",
    "    print(dummy_mode.weight.data)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"output2.csv\"\n",
    "import csv\n",
    "# Writing to csv file\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    # Create a csv writer object\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    \n",
    "    # Write each row to the csv file\n",
    "    for row in tem:\n",
    "        csvwriter.writerow([row])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
